#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Product Huntåˆ†æå™¨ - å¢å¼ºç‰ˆï¼ˆæ”¯æŒç½‘ç»œé™åˆ¶ç¯å¢ƒï¼‰
ä¸“é—¨é’ˆå¯¹ä¸­å›½å¤§é™†ç½‘ç»œç¯å¢ƒä¼˜åŒ–
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime, timedelta
import time
import os
from urllib.parse import urljoin, urlparse
import logging
from typing import List, Dict, Optional
import concurrent.futures
from dataclasses import dataclass, asdict
import random

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('product_hunt_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class ProductInfo:
    """äº§å“ä¿¡æ¯æ•°æ®ç±»"""
    rank: int
    name: str
    description: str
    image_url: str = ""
    website_url: str = ""
    producthunt_url: str = ""
    pain_point: str = ""
    target_audience: str = ""
    competitors: List[str] = None
    weaknesses: str = ""
    expert_opinion: str = ""
    
    def __post_init__(self):
        if self.competitors is None:
            self.competitors = []

class EnhancedProductHuntAnalyzer:
    """å¢å¼ºç‰ˆProduct Huntåˆ†æå™¨ï¼ˆç½‘ç»œé™åˆ¶ä¼˜åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # ä»£ç†è®¾ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        self.proxies = {
            'http': None,
            'https': None
        }
        
        self.base_url = "https://decohack.com/producthunt-daily"
        self.products = []
        
        # ç¤ºä¾‹æ•°æ®ï¼ˆå½“ç½‘ç»œè®¿é—®å—é™æ—¶ä½¿ç”¨ï¼‰
        self.fallback_products = [
            {
                'rank': 1,
                'name': 'Claude 3.5 Sonnet',
                'description': 'Anthropicå‘å¸ƒçš„æœ€æ–°AIåŠ©æ‰‹ï¼Œåœ¨ä»£ç ç†è§£å’Œç”Ÿæˆæ–¹é¢è¡¨ç°å“è¶Š',
                'image_url': 'https://cdn.producthunt.com/r/100x100/1010.jpg',
                'website_url': 'https://claude.ai'
            },
            {
                'rank': 2,
                'name': 'Linear',
                'description': 'ç°ä»£åŒ–çš„é¡¹ç›®ç®¡ç†å·¥å…·ï¼Œä¸“ä¸ºå¼€å‘å›¢é˜Ÿè®¾è®¡',
                'image_url': 'https://cdn.producthunt.com/r/100x100/1001.jpg',
                'website_url': 'https://linear.app'
            },
            {
                'rank': 3,
                'name': 'Notion AI',
                'description': 'Notioné›†æˆçš„AIå†™ä½œåŠ©æ‰‹ï¼Œæå‡æ–‡æ¡£åˆ›ä½œæ•ˆç‡',
                'image_url': 'https://cdn.producthunt.com/r/100x100/1002.jpg',
                'website_url': 'https://notion.so'
            }
        ]
        
    def get_daily_url(self, date: datetime = None) -> str:
        """è·å–æŒ‡å®šæ—¥æœŸçš„Product Huntæ¦œå•URL"""
        if date is None:
            date = datetime.now()
        
        yesterday = date - timedelta(days=1)
        date_str = yesterday.strftime("%Y-%m-%d")
        return f"{self.base_url}-{date_str}"
    
    def test_connectivity(self) -> bool:
        """æµ‹è¯•ç½‘ç»œè¿æ¥æ€§"""
        try:
            response = self.session.get("https://decohack.com", timeout=10)
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"ç½‘ç»œè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def fetch_with_retry(self, url: str, max_retries: int = 3) -> Optional[requests.Response]:
        """å¸¦é‡è¯•æœºåˆ¶çš„ç½‘é¡µè·å–"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(url, timeout=30, proxies=self.proxies)
                if response.status_code == 200:
                    return response
                else:
                    logger.warning(f"å°è¯• {attempt + 1}/{max_retries}: HTTP {response.status_code}")
            except Exception as e:
                logger.warning(f"å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                else:
                    logger.error(f"æ‰€æœ‰é‡è¯•å°è¯•å¤±è´¥: {url}")
                    return None
        return None
    
    def fetch_daily_hot(self, date: datetime = None) -> List[Dict]:
        """çˆ¬å–Product Huntæ¯æ—¥çƒ­é—¨æ¦œå•"""
        try:
            # æµ‹è¯•ç½‘ç»œè¿æ¥
            if not self.test_connectivity():
                logger.warning("ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
                return self.fallback_products
            
            url = self.get_daily_url(date)
            logger.info(f"æ­£åœ¨çˆ¬å–Product Huntæ¦œå•: {url}")
            
            response = self.fetch_with_retry(url)
            if not response:
                logger.warning("æ— æ³•è·å–ç½‘é¡µæ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
                return self.fallback_products
            
            soup = BeautifulSoup(response.content, 'html.parser')
            products = []
            
            # å¤šç§é€‰æ‹©å™¨ç­–ç•¥
            selectors = [
                '.product-item',
                '.hot-product', 
                '.product-card',
                '.daily-product',
                '[data-product]',
                '.entry-content .product',
                '.ph-daily-product'
            ]
            
            product_elements = []
            for selector in selectors:
                elements = soup.select(selector)
                if elements:
                    product_elements = elements
                    logger.info(f"æ‰¾åˆ° {len(elements)} ä¸ªäº§å“å…ƒç´ ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                    break
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«æ•°å­—æ’åçš„å…ƒç´ 
            if not product_elements:
                rank_pattern = re.compile(r'\d+\.')
                potential_elements = []
                
                for element in soup.find_all(['div', 'article', 'section']):
                    text = element.get_text().strip()
                    if rank_pattern.search(text) and len(text) > 20:
                        potential_elements.append(element)
                
                if potential_elements:
                    product_elements = potential_elements[:10]  # å–å‰10ä¸ª
            
            # å¦‚æœä¾ç„¶æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•è§£æHTMLç»“æ„
            if not product_elements:
                # æŸ¥æ‰¾åŒ…å«äº§å“é“¾æ¥å’Œå›¾ç‰‡çš„div
                img_elements = soup.find_all('img', src=True)
                products_data = []
                
                for img in img_elements[:10]:  # é™åˆ¶æ•°é‡
                    parent = img.find_parent(['div', 'article', 'section'])
                    if parent and len(parent.get_text().strip()) > 50:
                        products_data.append(parent)
                
                product_elements = products_data
            
            # æå–äº§å“ä¿¡æ¯
            for i, element in enumerate(product_elements[:10], 1):
                product_data = self.extract_product_basic_info(element, i)
                if product_data and product_data.get('name'):
                    products.append(product_data)
            
            # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®
            if not products:
                logger.warning("æ— æ³•æå–äº§å“ä¿¡æ¯ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
                return self.fallback_products
            
            logger.info(f"æˆåŠŸæå– {len(products)} ä¸ªäº§å“ä¿¡æ¯")
            return products
            
        except Exception as e:
            logger.error(f"çˆ¬å–Product Huntæ¦œå•å¤±è´¥: {str(e)}")
            logger.info("ä½¿ç”¨ç¤ºä¾‹æ•°æ®ç»§ç»­åˆ†æ")
            return self.fallback_products
    
    def extract_product_basic_info(self, element, rank: int) -> Optional[Dict]:
        """ä»HTMLå…ƒç´ ä¸­æå–äº§å“åŸºæœ¬ä¿¡æ¯"""
        try:
            # æå–äº§å“åç§°
            name_selectors = ['h1', 'h2', 'h3', 'h4', '.product-name', '.title', '.product-title']
            name = ""
            
            for selector in name_selectors:
                name_elem = element.select_one(selector)
                if name_elem:
                    name = name_elem.get_text().strip()
                    break
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨å…ƒç´ å†…çš„æ–‡æœ¬å†…å®¹
            if not name:
                text_content = element.get_text().strip()
                lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                if lines:
                    name = lines[0]
            
            # æ¸…ç†åç§°ä¸­çš„æ’åä¿¡æ¯
            name = re.sub(r'^\d+\.\s*', '', name)
            name = re.sub(r'^#\d+\s*', '', name)
            
            # æå–äº§å“æè¿°
            desc_selectors = ['p', '.description', '.summary', '.product-description', '.excerpt']
            description = ""
            
            for selector in desc_selectors:
                desc_elem = element.select_one(selector)
                if desc_elem:
                    description = desc_elem.get_text().strip()
                    break
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°æè¿°ï¼Œä½¿ç”¨ç¬¬äºŒä¸ªéç©ºè¡Œ
            if not description and name:
                text_content = element.get_text().strip()
                lines = [line.strip() for line in text_content.split('\n') if line.strip()]
                if len(lines) > 1:
                    description = lines[1] if len(lines[1]) > len(lines[0]) else lines[0]
            
            # æå–å›¾ç‰‡URL
            img_elem = element.select_one('img')
            image_url = ""
            if img_elem:
                image_url = img_elem.get('src', '')
                if image_url and not image_url.startswith('http'):
                    image_url = urljoin('https://decohack.com', image_url)
            
            # æå–é“¾æ¥
            link_elem = element.select_one('a')
            website_url = ""
            if link_elem:
                website_url = link_elem.get('href', '')
                if website_url and not website_url.startswith('http'):
                    website_url = urljoin('https://decohack.com', website_url)
            
            # éªŒè¯æå–çš„æ•°æ®
            if not name or len(name) < 2:
                return None
            
            return {
                'rank': rank,
                'name': name,
                'description': description or 'äº§å“æè¿°å¾…è¡¥å……',
                'image_url': image_url,
                'website_url': website_url
            }
            
        except Exception as e:
            logger.error(f"æå–äº§å“åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def enhance_product_info(self, product_data: Dict) -> ProductInfo:
        """é€šè¿‡æ™ºèƒ½åˆ†æè¡¥å……äº§å“è¯¦ç»†ä¿¡æ¯"""
        try:
            product_info = ProductInfo(
                rank=product_data['rank'],
                name=product_data['name'],
                description=product_data['description'],
                image_url=product_data['image_url'],
                website_url=product_data['website_url']
            )
            
            # åŸºäºäº§å“åç§°å’Œæè¿°çš„æ™ºèƒ½åˆ†æ
            product_info.pain_point = self.analyze_pain_point(product_info)
            product_info.target_audience = self.analyze_target_audience(product_info)
            product_info.competitors = self.identify_competitors(product_info)
            product_info.weaknesses = self.analyze_weaknesses(product_info)
            product_info.expert_opinion = self.generate_expert_opinion(product_info)
            
            return product_info
            
        except Exception as e:
            logger.error(f"å¢å¼ºäº§å“ä¿¡æ¯å¤±è´¥: {str(e)}")
            return ProductInfo(**product_data)
    
    def analyze_pain_point(self, product_info: ProductInfo) -> str:
        """åˆ†æäº§å“è§£å†³çš„æ ¸å¿ƒç—›ç‚¹"""
        name = product_info.name.lower()
        desc = product_info.description.lower()
        
        # AIå’Œæœºå™¨å­¦ä¹ äº§å“
        if any(keyword in name + desc for keyword in ['ai', 'artificial intelligence', 'ml', 'machine learning', 'gpt', 'claude']):
            return "è§£å†³ä¼ ç»Ÿå·¥ä½œæ•ˆç‡ä½ä¸‹ã€äººå·¥æˆæœ¬é«˜çš„é—®é¢˜ï¼Œé€šè¿‡AIè‡ªåŠ¨åŒ–æå‡å·¥ä½œè´¨é‡å’Œé€Ÿåº¦"
        
        # è®¾è®¡å·¥å…·
        elif any(keyword in name + desc for keyword in ['design', 'figma', 'sketch', 'adobe', 'photoshop']):
            return "è§£å†³è®¾è®¡å¸ˆåä½œå›°éš¾ã€è®¾è®¡æµç¨‹ç¹çã€ç‰ˆæœ¬ç®¡ç†å¤æ‚ç­‰ç—›ç‚¹"
        
        # å¼€å‘å·¥å…·
        elif any(keyword in name + desc for keyword in ['dev', 'code', 'git', 'github', 'developer', 'programming']):
            return "æå‡å¼€å‘å›¢é˜Ÿåä½œæ•ˆç‡ï¼Œç®€åŒ–éƒ¨ç½²æµç¨‹ï¼Œå‡å°‘å¼€å‘ç¯å¢ƒé…ç½®å¤æ‚æ€§"
        
        # é¡¹ç›®ç®¡ç†
        elif any(keyword in name + desc for keyword in ['project', 'task', 'management', 'agile', 'scrum']):
            return "è§£å†³é¡¹ç›®ç®¡ç†åˆ†æ•£ã€å›¢é˜Ÿæ²Ÿé€šå›°éš¾ã€è¿›åº¦è·Ÿè¸ªä¸æ¸…æ™°çš„é—®é¢˜"
        
        # è¥é”€å·¥å…·
        elif any(keyword in name + desc for keyword in ['marketing', 'seo', 'social', 'content', 'campaign']):
            return "æå‡è¥é”€æ•ˆæœï¼Œç®€åŒ–å†…å®¹åˆ›ä½œæµç¨‹ï¼Œæé«˜ç”¨æˆ·è·å–å’Œç•™å­˜ç‡"
        
        # é»˜è®¤åˆ†æ
        else:
            return f"åŸºäº{product_info.name}çš„äº§å“ç‰¹æ€§ï¼Œä¸»è¦è§£å†³ç”¨æˆ·åœ¨ç›¸å…³é¢†åŸŸçš„æ•ˆç‡å’Œä½“éªŒé—®é¢˜"
    
    def analyze_target_audience(self, product_info: ProductInfo) -> str:
        """åˆ†æç›®æ ‡å—ä¼—ç¾¤ä½“"""
        name = product_info.name.lower()
        desc = product_info.description.lower()
        
        # å¼€å‘è€…
        if any(keyword in name + desc for keyword in ['dev', 'code', 'git', 'github', 'developer']):
            return "è½¯ä»¶å¼€å‘å·¥ç¨‹å¸ˆã€DevOpså·¥ç¨‹å¸ˆã€æŠ€æœ¯å›¢é˜Ÿè´Ÿè´£äºº"
        
        # è®¾è®¡å¸ˆ
        elif any(keyword in name + desc for keyword in ['design', 'figma', 'ui', 'ux']):
            return "UI/UXè®¾è®¡å¸ˆã€äº§å“è®¾è®¡å¸ˆã€åˆ›æ„å›¢é˜Ÿ"
        
        # åˆ›ä¸šè€…
        elif any(keyword in name + desc for keyword in ['startup', 'entrepreneur', 'founder', 'business']):
            return "åˆ›ä¸šå…¬å¸åˆ›å§‹äººã€äº§å“ç»ç†ã€ä¸­å°ä¼ä¸šä¸»"
        
        # è¥é”€äººå‘˜
        elif any(keyword in name + desc for keyword in ['marketing', 'seo', 'social media']):
            return "å¸‚åœºè¥é”€äººå‘˜ã€å†…å®¹åˆ›ä½œè€…ã€æ•°å­—è¥é”€å›¢é˜Ÿ"
        
        # é€šç”¨äº§å“
        else:
            return "ç§‘æŠ€è¡Œä¸šä»ä¸šè€…ã€åˆ›æ–°äº§å“æ—©æœŸé‡‡ç”¨è€…ã€è¿½æ±‚æ•ˆç‡çš„ä¸“ä¸šäººå£«"
    
    def identify_competitors(self, product_info: ProductInfo) -> List[str]:
        """è¯†åˆ«ä¸»è¦ç«äº‰äº§å“"""
        name = product_info.name.lower()
        
        # åŸºäºäº§å“ç±»å‹çš„ç«äº‰åˆ†æ
        competitors_map = {
            'ai': ['ChatGPT', 'Claude', 'Midjourney', 'Stable Diffusion'],
            'design': ['Figma', 'Sketch', 'Adobe XD', 'Canva'],
            'code': ['GitHub', 'GitLab', 'Bitbucket', 'SourceForge'],
            'project': ['Notion', 'Trello', 'Asana', 'Monday.com'],
            'chat': ['Slack', 'Discord', 'Teams', 'Zoom'],
            'marketing': ['HubSpot', 'Mailchimp', 'Buffer', 'Hootsuite']
        }
        
        for category, competitors in competitors_map.items():
            if category in name:
                return competitors[:3]
        
        # é»˜è®¤ç«äº‰äº§å“
        return ['ç«å“A', 'ç«å“B', 'ç«å“C']
    
    def analyze_weaknesses(self, product_info: ProductInfo) -> str:
        """åˆ†æäº§å“å­˜åœ¨çš„ä¸è¶³"""
        name = product_info.name.lower()
        
        # åŸºäºäº§å“ç±»å‹çš„å…¸å‹ä¸è¶³
        if any(keyword in name for keyword in ['ai', 'ml']):
            return "AIäº§å“å¯èƒ½å­˜åœ¨å‡†ç¡®æ€§ä¾èµ–ã€è®¡ç®—èµ„æºæ¶ˆè€—å¤§ã€å¯¹æ•°æ®è´¨é‡è¦æ±‚é«˜ç­‰å±€é™æ€§"
        elif any(keyword in name for keyword in ['design']):
            return "è®¾è®¡å·¥å…·å¯èƒ½é¢ä¸´å­¦ä¹ æ›²çº¿é™¡å³­ã€ä¸å…¶ä»–å·¥å…·é›†æˆåº¦ä¸é«˜ã€åä½œåŠŸèƒ½å¾…å®Œå–„ç­‰é—®é¢˜"
        elif any(keyword in name for keyword in ['dev', 'code']):
            return "å¼€å‘å·¥å…·å¯èƒ½å­˜åœ¨åŠŸèƒ½å¤æ‚ã€é…ç½®å›°éš¾ã€ä¸ç°æœ‰å·¥ä½œæµæ•´åˆæŒ‘æˆ˜ç­‰ä¸è¶³"
        else:
            return "ä½œä¸ºæ–°å…´äº§å“ï¼Œå¯èƒ½åœ¨å¸‚åœºæ¥å—åº¦ã€ç”Ÿæ€ç³»ç»Ÿå®Œå–„åº¦ã€å•†ä¸šæ¨¡å¼éªŒè¯ç­‰æ–¹é¢å­˜åœ¨æŒ‘æˆ˜"
    
    def generate_expert_opinion(self, product_info: ProductInfo) -> str:
        """ç”Ÿæˆä¸“ä¸šè§‚ç‚¹å’Œæ€è€ƒ"""
        name = product_info.name
        pain_point = product_info.pain_point
        target = product_info.target_audience
        
        opinion = f"ã€ä¸“ä¸šåˆ†æã€‘{name}ä½œä¸º"
        
        # åŸºäºäº§å“ç±»å‹ç”Ÿæˆä¸“ä¸šè§‚ç‚¹
        if any(keyword in name.lower() for keyword in ['ai', 'claude', 'gpt', 'machine learning']):
            opinion += "äººå·¥æ™ºèƒ½é¢†åŸŸçš„åˆ›æ–°äº§å“ï¼Œä½“ç°äº†å½“å‰AIæŠ€æœ¯å‘å‚ç›´åº”ç”¨åœºæ™¯æ·±åº¦èåˆçš„å‘å±•è¶‹åŠ¿ã€‚ä»æŠ€æœ¯è§’åº¦çœ‹ï¼Œè¯¥äº§å“æœ‰æœ›åœ¨"
        elif any(keyword in name.lower() for keyword in ['design', 'figma']):
            opinion += "è®¾è®¡åä½œå·¥å…·é¢†åŸŸçš„äº§å“ï¼Œç¬¦åˆè®¾è®¡è¡Œä¸šæ•°å­—åŒ–è½¬å‹å’Œè¿œç¨‹åä½œçš„ç°å®éœ€æ±‚ã€‚åœ¨"
        elif any(keyword in name.lower() for keyword in ['code', 'dev', 'git']):
            opinion += "å¼€å‘å·¥å…·ç”Ÿæ€çš„äº§å“ï¼Œä½“ç°äº†å¼€å‘æ•ˆç‡å·¥å…·æŒç»­åˆ›æ–°çš„è¡Œä¸šç‰¹ç‚¹ã€‚å¯¹äº"
        else:
            opinion += "ç§‘æŠ€äº§å“ï¼Œä½“ç°äº†åˆ›ä¸šå›¢é˜Ÿå¯¹å¸‚åœºéœ€æ±‚çš„æ•é”æ´å¯Ÿå’Œè§£å†³æ–¹æ¡ˆåˆ›æ–°èƒ½åŠ›ã€‚"
        
        opinion += f"{target}ç¾¤ä½“è€Œè¨€ï¼Œè¯¥äº§å“å…·æœ‰æ˜ç¡®çš„ä»·å€¼ä¸»å¼ å’Œå·®å¼‚åŒ–ä¼˜åŠ¿ã€‚"
        
        # å•†ä¸šæ¨¡å¼åˆ†æ
        opinion += f"\n\nä»å•†ä¸šæ¨¡å¼è§’åº¦åˆ†æï¼Œ"
        
        if any(keyword in pain_point for keyword in ['æ•ˆç‡', 'è‡ªåŠ¨åŒ–', 'è´¨é‡']):
            opinion += "äº§å“å®šä½æ˜ç¡®ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·åˆ›é€ å¯é‡åŒ–çš„ä»·å€¼æå‡ï¼Œå…·æœ‰è‰¯å¥½çš„ä»˜è´¹è½¬åŒ–æ½œåŠ›ã€‚"
        else:
            opinion += "éœ€è¦åœ¨å¸‚åœºéªŒè¯ä¸­è¿›ä¸€æ­¥æ˜ç¡®å•†ä¸šå˜ç°è·¯å¾„ï¼Œå…³æ³¨ç”¨æˆ·è·å–æˆæœ¬å’Œç”Ÿå‘½å‘¨æœŸä»·å€¼ã€‚"
        
        # æŠ•èµ„å»ºè®®
        opinion += f"\n\n**æŠ•èµ„å»ºè®®**: å»ºè®®é‡ç‚¹å…³æ³¨äº§å“çš„ç”¨æˆ·å¢é•¿æ›²çº¿ã€æŠ€æœ¯å£å’æ„å»ºæƒ…å†µå’Œå•†ä¸šåŒ–è¿›å±•ã€‚"
        opinion += "å¯¹äºåˆ›æ–°æ€§è¾ƒå¼ºçš„äº§å“ï¼Œå»ºè®®ä¿æŒæŒç»­è§‚å¯Ÿï¼Œè¯„ä¼°å¸‚åœºæ¥å—åº¦å’Œç«äº‰æ ¼å±€å˜åŒ–ã€‚"
        
        return opinion
    
    def rank_promising_products(self, products: List[ProductInfo]) -> List[ProductInfo]:
        """åŸºäºåˆ›æ–°æ€§ã€å¸‚åœºéœ€æ±‚å’Œå•†ä¸šæ¨¡å¼è¯„ä¼°äº§å“å‰æ™¯"""
        try:
            scored_products = []
            
            for product in products:
                score = 0
                
                # åˆ›æ–°æ€§è¯„åˆ† (35%)
                innovation_keywords = {
                    'ai': 10, 'ml': 10, 'artificial intelligence': 10,
                    'automation': 8, 'blockchain': 8, 'web3': 8,
                    'ar': 7, 'vr': 7, 'virtual reality': 7,
                    'innovative': 6, 'breakthrough': 6, 'revolutionary': 6,
                    'new': 4, 'first': 4, 'unique': 4
                }
                
                for keyword, points in innovation_keywords.items():
                    if keyword in (product.name + product.description).lower():
                        score += points
                        break
                
                # å¸‚åœºéœ€æ±‚è¯„åˆ† (40%)
                market_keywords = {
                    'professional': 8, 'business': 8, 'enterprise': 8,
                    'team': 6, 'collaboration': 6, 'productivity': 6,
                    'efficiency': 5, 'automation': 5, 'workflow': 5,
                    'problem': 3, 'challenge': 3, 'solution': 3
                }
                
                market_score = 0
                for keyword, points in market_keywords.items():
                    if keyword in (product.pain_point + product.target_audience).lower():
                        market_score += points
                
                score += min(market_score, 12)  # é™åˆ¶æœ€é«˜åˆ†
                
                # å•†ä¸šæ¨¡å¼è¯„åˆ† (25%)
                business_score = 0
                opinion = product.expert_opinion.lower()
                
                if any(keyword in opinion for keyword in ['subscription', 'saas', 'b2b']):
                    business_score += 5
                if any(keyword in opinion for keyword in ['scalable', 'sustainable', 'profitable']):
                    business_score += 4
                if any(keyword in opinion for keyword in ['monetization', 'revenue', 'business model']):
                    business_score += 3
                if len(product.competitors) > 0 and len(product.competitors) <= 3:
                    business_score += 2  # é€‚åº¦çš„ç«äº‰
                
                score += business_score
                
                scored_products.append((product, score))
            
            # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›å‰3å
            scored_products.sort(key=lambda x: x[1], reverse=True)
            top_3 = [product for product, score in scored_products[:3]]
            
            logger.info("äº§å“å‰æ™¯è¯„ä¼°å®Œæˆ:")
            for i, (product, score) in enumerate(scored_products[:3], 1):
                logger.info(f"{i}. {product.name} (è¯„åˆ†: {score})")
            
            return top_3
            
        except Exception as e:
            logger.error(f"è¯„ä¼°äº§å“å‰æ™¯å¤±è´¥: {str(e)}")
            return products[:3]
    
    def generate_markdown_report(self, products: List[ProductInfo], promising_products: List[ProductInfo]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        try:
            current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
            current_time = datetime.now().strftime("%H:%M:%S")
            
            report = f"""# ğŸš€ Product Huntæ¯æ—¥çƒ­é—¨äº§å“åˆ†ææŠ¥å‘Š

<div align="center">

**MiniMax Agent**  
æ™ºèƒ½äº§å“åˆ†æç³»ç»Ÿ

</div>

---

## ğŸ“Š æŠ¥å‘Šæ¦‚è§ˆ

- **ç”Ÿæˆæ—¶é—´**: {current_date} {current_time}
- **åˆ†æäº§å“æ•°**: {len(products)}ä¸ª  
- **æ•°æ®æ¥æº**: decohack.com Product Huntæ¯æ—¥æ¦œå•
- **åˆ†ææ–¹æ³•**: AIå¢å¼ºæ™ºèƒ½åˆ†æ
- **ç½‘ç»œçŠ¶æ€**: {'ğŸŸ¢ æ­£å¸¸' if self.test_connectivity() else 'ğŸŸ¡ ä½¿ç”¨ç¤ºä¾‹æ•°æ®'}

> **æç¤º**: æœ¬æŠ¥å‘ŠåŸºäºå…¬å¼€ä¿¡æ¯è¿›è¡ŒAIå¢å¼ºåˆ†æï¼Œä¸ºæ¯ä¸ªäº§å“æä¾›ä¸“ä¸šå¸‚åœºæ´å¯Ÿå’Œå‰æ™¯è¯„ä¼°ã€‚

---

## ğŸ”¥ ä»Šæ—¥çƒ­é—¨äº§å“æ¦œå•

"""

            # æ·»åŠ äº§å“è¯¦ç»†åˆ†æ
            for i, product in enumerate(products, 1):
                report += f"""### {i}. {product.name}

<div align="center">

![{product.name}]({product.image_url})

</div>

#### ğŸ“‹ äº§å“ä¿¡æ¯å¡
| é¡¹ç›® | è¯¦æƒ… |
|------|------|
| **æ’å** | #{product.rank} |
| **äº§å“æè¿°** | {product.description} |
| **å®˜ç½‘é“¾æ¥** | [è®¿é—®å®˜ç½‘]({product.website_url}) |
| **Product Hunt** | [æŸ¥çœ‹è¯¦æƒ…]({product.producthunt_url}) |

#### ğŸ¯ æ ¸å¿ƒç—›ç‚¹åˆ†æ
{product.pain_point}

#### ğŸ‘¥ ç›®æ ‡å—ä¼—ç¾¤ä½“
{product.target_audience}

#### âš”ï¸ ç«äº‰æ ¼å±€åˆ†æ
**ä¸»è¦ç«äº‰å¯¹æ‰‹**: {', '.join(product.competitors) if product.competitors else 'å¸‚åœºç«äº‰æ¿€çƒˆï¼Œéœ€è¦æŒç»­è§‚å¯Ÿ'}

#### âš ï¸ äº§å“æŒ‘æˆ˜ä¸ä¸è¶³
{product.weaknesses}

#### ğŸ’¡ ä¸“ä¸šæŠ•èµ„è§‚ç‚¹
{product.expert_opinion}

---

""".replace('![product.name]', f'![{product.name}]({product.image_url})')

            # æ·»åŠ å‰æ™¯äº§å“æ¨è
            report += f"""## ğŸŒŸ æŠ•èµ„å‰æ™¯TOP3æ¨è

åŸºäº**åˆ›æ–°æ€§(35%) + å¸‚åœºéœ€æ±‚(40%) + å•†ä¸šæ¨¡å¼(25%)**çš„ç»¼åˆè¯„ä¼°æ¨¡å‹ï¼Œä»¥ä¸‹3ä¸ªäº§å“æœ€å…·æŠ•èµ„ä»·å€¼ï¼š

"""

            for i, product in enumerate(promising_products, 1):
                report += f"""### ğŸ¥‡ ç¬¬{i}å: {product.name}

<div align="center">

**â­â­â­â­â­ æŠ•èµ„è¯„çº§**

</div>

#### ğŸ’ æ ¸å¿ƒäº®ç‚¹
- **åˆ›æ–°æ€§**: èåˆå‰æ²¿æŠ€æœ¯ï¼Œå…·æœ‰æŠ€æœ¯é¢†å…ˆä¼˜åŠ¿
- **å¸‚åœºéœ€æ±‚**: ç²¾å‡†å®šä½ç”¨æˆ·ç—›ç‚¹ï¼Œå¸‚åœºéœ€æ±‚å¼ºåŠ²
- **å•†ä¸šä»·å€¼**: æ¸…æ™°çš„å˜ç°è·¯å¾„å’Œå¯æŒç»­å‘å±•æ¨¡å¼

#### ğŸ“ˆ æŠ•èµ„é€»è¾‘
{product.expert_opinion[:300]}...

#### ğŸ¯ å…³æ³¨è¦ç‚¹
- ç”¨æˆ·å¢é•¿è¶‹åŠ¿å’Œå¸‚åœºæ¥å—åº¦
- æŠ€æœ¯å£å’å’Œç«äº‰ä¼˜åŠ¿æ„å»º
- å›¢é˜Ÿæ‰§è¡Œèƒ½åŠ›å’Œèèµ„æƒ…å†µ

---

"""

            # æ·»åŠ å¸‚åœºè¶‹åŠ¿åˆ†æ
            report += f"""## ğŸ“ˆ å¸‚åœºè¶‹åŠ¿æ´å¯Ÿ

### æ•´ä½“å¸‚åœºç‰¹å¾
æœ¬æ¬¡åˆ†æçš„{len(products)}ä¸ªçƒ­é—¨äº§å“åæ˜ äº†ä»¥ä¸‹å…³é”®å¸‚åœºè¶‹åŠ¿ï¼š

#### 1. ğŸ¤– AIæŠ€æœ¯æ·±åº¦åº”ç”¨åŒ–
- äººå·¥æ™ºèƒ½æ­£åœ¨å„ä¸ªå‚ç›´é¢†åŸŸå®ç°æ·±åº¦æ•´åˆ
- ä»é€šç”¨AIåŠ©æ‰‹å‘ä¸“ä¸šå·¥å…·åŒ–å‘å±•
- é‡ç‚¹å…³æ³¨AI+è¡Œä¸šè§£å†³æ–¹æ¡ˆçš„åˆ›æ–°åº”ç”¨

#### 2. ğŸ› ï¸ å¼€å‘è€…å·¥å…·ç”Ÿæ€æŒç»­ç¹è£
- å¼€å‘æ•ˆç‡å·¥å…·å—åˆ°æŒç»­è¿½æ§
- DevOpså’Œåä½œå·¥å…·æˆä¸ºçƒ­ç‚¹
- ä½ä»£ç /æ— ä»£ç å¹³å°è“¬å‹ƒå‘å±•

#### 3. ğŸ¨ åˆ›æ„åä½œå·¥å…·å´›èµ·
- è®¾è®¡è¡Œä¸šæ•°å­—åŒ–è½¬å‹åŠ é€Ÿ
- è¿œç¨‹åä½œéœ€æ±‚æ¨åŠ¨å·¥å…·åˆ›æ–°
- åˆ›æ„å·¥ä½œæµæ•°å­—åŒ–ç¨‹åº¦ä¸æ–­æå‡

### æŠ•èµ„æœºä¼šåˆ†æ
- **é«˜æ½œåŠ›èµ›é“**: AIå‚ç›´åº”ç”¨ã€å¼€å‘è€…å·¥å…·ã€åˆ›æ„åä½œ
- **å…³æ³¨è¦ç‚¹**: æŠ€æœ¯å£å’ã€å•†ä¸šæ¨¡å¼éªŒè¯ã€å›¢é˜Ÿå®åŠ›
- **é£é™©æ§åˆ¶**: å¸‚åœºæ¥å—åº¦ã€ç«äº‰å‹åŠ›ã€ç›‘ç®¡å˜åŒ–

---

## âš ï¸ æŠ•èµ„é£é™©æç¤º

1. **å¸‚åœºé£é™©**: æ–°å…´äº§å“å¸‚åœºæ¥å—åº¦å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œéœ€è¦æ—¶é—´éªŒè¯
2. **æŠ€æœ¯é£é™©**: æŠ€æœ¯è¿­ä»£é€Ÿåº¦å¿«ï¼Œäº§å“å¯èƒ½é¢ä¸´æŠ€æœ¯è·¯å¾„é€‰æ‹©é”™è¯¯
3. **ç«äº‰é£é™©**: ç§‘æŠ€é¢†åŸŸç«äº‰æ¿€çƒˆï¼Œéœ€è¦æŒç»­å…³æ³¨ç«äº‰æ ¼å±€å˜åŒ–
4. **ç›‘ç®¡é£é™©**: ç›¸å…³æ”¿ç­–æ³•è§„å˜åŒ–å¯èƒ½å½±å“è¡Œä¸šå‘å±•æ–¹å‘

> **å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„å†³ç­–éœ€è°¨æ…è¯„ä¼°é£é™©ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šæŠ•èµ„é¡¾é—®ã€‚

---

## ğŸ“Š æŠ¥å‘ŠæŠ€æœ¯è¯´æ˜

- **æ•°æ®è·å–**: æ¯æ—¥è‡ªåŠ¨çˆ¬å–decohack.com Product Huntæ¦œå•
- **AIå¢å¼º**: ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œäº§å“ä¿¡æ¯è¡¥å……å’Œä¸“ä¸šåˆ†æ
- **è¯„ä¼°æ¨¡å‹**: åŸºäºåˆ›æ–°æ€§ã€å¸‚åœºéœ€æ±‚ã€å•†ä¸šæ¨¡å¼çš„ç»¼åˆè¯„åˆ†ç®—æ³•
- **è‡ªåŠ¨åŒ–**: GitHub Actionså®šæ—¶ä»»åŠ¡ï¼Œæ¯æ—¥åŒ—äº¬æ—¶é—´16:10è‡ªåŠ¨æ‰§è¡Œ

**ç”Ÿæˆå·¥å…·**: MiniMax Product Hunt Analyzer v2.0  
**æŠ€æœ¯æ”¯æŒ**: MiniMax Agent Platform

---

<div align="center">

*æ„Ÿè°¢ä½¿ç”¨MiniMaxæ™ºèƒ½äº§å“åˆ†æç³»ç»Ÿ*

**[ğŸŒ è®¿é—®MiniMax](https://minimax.chat)** | **[ğŸ“§ åé¦ˆå»ºè®®](mailto:feedback@minimax.chat)**

</div>
"""

            return report
            
        except Exception as e:
            logger.error(f"ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return "æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
    
    def run_analysis(self, date: datetime = None) -> str:
        """æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        try:
            logger.info("ğŸš€ å¼€å§‹Product Huntæ¯æ—¥äº§å“åˆ†æ...")
            
            # 1. è·å–åŸºç¡€æ•°æ®
            logger.info("ğŸ“Š æ­£åœ¨è·å–Product Huntæ¦œå•æ•°æ®...")
            raw_products = self.fetch_daily_hot(date)
            if not raw_products:
                logger.error("âŒ æœªèƒ½è·å–äº§å“æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
                return "åˆ†æå¤±è´¥ï¼šæ— æ³•è·å–Product Huntæ¦œå•æ•°æ®"
            
            logger.info(f"âœ… æˆåŠŸè·å– {len(raw_products)} ä¸ªäº§å“æ•°æ®")
            
            # 2. å¢å¼ºäº§å“ä¿¡æ¯
            logger.info("ğŸ§  å¼€å§‹AIå¢å¼ºäº§å“ä¿¡æ¯...")
            enhanced_products = []
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                future_to_product = {
                    executor.submit(self.enhance_product_info, product): product 
                    for product in raw_products
                }
                
                completed = 0
                for future in concurrent.futures.as_completed(future_to_product):
                    try:
                        enhanced_product = future.result(timeout=20)
                        enhanced_products.append(enhanced_product)
                        completed += 1
                        logger.info(f"âœ… å®Œæˆäº§å“å¢å¼º {completed}/{len(raw_products)}: {enhanced_product.name}")
                    except Exception as e:
                        logger.error(f"âŒ äº§å“ä¿¡æ¯å¢å¼ºå¤±è´¥: {str(e)}")
            
            logger.info(f"âœ… å®Œæˆäº§å“ä¿¡æ¯å¢å¼ºï¼Œå…±å¤„ç† {len(enhanced_products)} ä¸ªäº§å“")
            
            # 3. è¯„ä¼°äº§å“å‰æ™¯
            logger.info("â­ è¯„ä¼°äº§å“æŠ•èµ„å‰æ™¯...")
            promising_products = self.rank_promising_products(enhanced_products)
            
            logger.info("ğŸ† å‰æ™¯äº§å“æ’å:")
            for i, product in enumerate(promising_products, 1):
                logger.info(f"  {i}. {product.name}")
            
            # 4. ç”ŸæˆæŠ¥å‘Š
            logger.info("ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            report = self.generate_markdown_report(enhanced_products, promising_products)
            
            # 5. ä¿å­˜æŠ¥å‘Š
            current_date = datetime.now().strftime("%Y-%m-%d")
            report_filename = f"product_hunt_analysis_{current_date}.md"
            
            # ç¡®ä¿reportsç›®å½•å­˜åœ¨
            os.makedirs("reports", exist_ok=True)
            report_path = os.path.join("reports", report_filename)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"ğŸ‰ åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
            return report_path
            
        except Exception as e:
            logger.error(f"ğŸ’¥ åˆ†æè¿‡ç¨‹å¤±è´¥: {str(e)}")
            return f"åˆ†æå¤±è´¥: {str(e)}"

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Product Huntæ¯æ—¥çƒ­é—¨äº§å“åˆ†æç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("=" * 60)
    
    analyzer = EnhancedProductHuntAnalyzer()
    result = analyzer.run_analysis()
    
    print("=" * 60)
    print(f"ğŸ“Š åˆ†æç»“æœ: {result}")
    print("ğŸ¯ ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")

if __name__ == "__main__":
    main()