#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Product Huntæ¯æ—¥çƒ­é—¨äº§å“åˆ†æç³»ç»Ÿ
è‡ªåŠ¨çˆ¬å–ã€åˆ†æå’Œç”ŸæˆProduct Huntçƒ­é—¨äº§å“çš„è¯¦ç»†æŠ¥å‘Š
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime, timedelta
import time
import os
from urllib.parse import urljoin, urlparse
import logging
from typing import List, Dict, Optional
import concurrent.futures
from dataclasses import dataclass, asdict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('product_hunt_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class ProductInfo:
    """äº§å“ä¿¡æ¯æ•°æ®ç±»"""
    rank: int
    name: str
    description: str
    image_url: str = ""
    website_url: str = ""
    producthunt_url: str = ""
    pain_point: str = ""
    target_audience: str = ""
    competitors: List[str] = None
    weaknesses: str = ""
    expert_opinion: str = ""
    
    def __post_init__(self):
        if self.competitors is None:
            self.competitors = []

class ProductHuntAnalyzer:
    """Product Huntåˆ†æå™¨ä¸»ç±»"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.base_url = "https://decohack.com/producthunt-daily"
        self.products = []
        
    def get_daily_url(self, date: datetime = None) -> str:
        """è·å–æŒ‡å®šæ—¥æœŸçš„Product Huntæ¦œå•URL"""
        if date is None:
            date = datetime.now()
        
        # ä½¿ç”¨å‰ä¸€å¤©çš„æ—¥æœŸï¼Œå› ä¸ºProduct Huntæ¦œå•é€šå¸¸åœ¨å½“æ—¥å‡Œæ™¨å‘å¸ƒ
        yesterday = date - timedelta(days=1)
        date_str = yesterday.strftime("%Y-%m-%d")
        return f"{self.base_url}-{date_str}"
    
    def fetch_daily_hot(self, date: datetime = None) -> List[Dict]:
        """çˆ¬å–Product Huntæ¯æ—¥çƒ­é—¨æ¦œå•"""
        try:
            url = self.get_daily_url(date)
            logger.info(f"æ­£åœ¨çˆ¬å–Product Huntæ¦œå•: {url}")
            
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            products = []
            
            # å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨æ¥æ‰¾åˆ°äº§å“ä¿¡æ¯
            product_selectors = [
                '.product-item',
                '.hot-product',
                '.product-card',
                '.daily-product',
                '.ph-product'
            ]
            
            product_elements = []
            for selector in product_selectors:
                elements = soup.select(selector)
                if elements:
                    product_elements = elements
                    logger.info(f"æ‰¾åˆ° {len(elements)} ä¸ªäº§å“å…ƒç´ ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                    break
            
            if not product_elements:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šé€‰æ‹©å™¨ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«äº§å“ä¿¡æ¯çš„é€šç”¨å…ƒç´ 
                potential_products = soup.find_all(['div', 'article'], class_=re.compile(r'.*product.*|.*hot.*|.*daily.*'))
                if potential_products:
                    product_elements = potential_products
            
            if not product_elements:
                logger.warning("æœªæ‰¾åˆ°äº§å“å…ƒç´ ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³å…ƒç´ ")
                # æœ€åå°è¯•ï¼šæŸ¥æ‰¾åŒ…å«æ’åä¿¡æ¯çš„å…ƒç´ 
                all_elements = soup.find_all(text=re.compile(r'^\d+\.'))
                for element in all_elements:
                    parent = element.parent
                    while parent and len(parent.get_text().strip()) < 200:
                        parent = parent.parent
                    if parent:
                        product_elements.append(parent)
            
            # æå–äº§å“ä¿¡æ¯
            for i, element in enumerate(product_elements[:10], 1):  # é™åˆ¶ä¸ºå‰10ä¸ªäº§å“
                product_data = self.extract_product_basic_info(element, i)
                if product_data:
                    products.append(product_data)
            
            logger.info(f"æˆåŠŸæå– {len(products)} ä¸ªäº§å“ä¿¡æ¯")
            return products
            
        except Exception as e:
            logger.error(f"çˆ¬å–Product Huntæ¦œå•å¤±è´¥: {str(e)}")
            return []
    
    def extract_product_basic_info(self, element, rank: int) -> Optional[Dict]:
        """ä»HTMLå…ƒç´ ä¸­æå–äº§å“åŸºæœ¬ä¿¡æ¯"""
        try:
            # æå–äº§å“åç§°
            name_selectors = ['h1', 'h2', 'h3', '.product-name', '.title']
            name = ""
            for selector in name_selectors:
                name_elem = element.select_one(selector)
                if name_elem:
                    name = name_elem.get_text().strip()
                    break
            
            # æ¸…ç†åç§°ä¸­çš„æ’åä¿¡æ¯
            name = re.sub(r'^\d+\.\s*', '', name)
            
            # æå–äº§å“æè¿°
            desc_selectors = ['p', '.description', '.summary', '.product-description']
            description = ""
            for selector in desc_selectors:
                desc_elem = element.select_one(selector)
                if desc_elem:
                    description = desc_elem.get_text().strip()
                    break
            
            # æå–å›¾ç‰‡URL
            img_elem = element.select_one('img')
            image_url = ""
            if img_elem:
                image_url = img_elem.get('src', '')
                if image_url and not image_url.startswith('http'):
                    image_url = urljoin('https://decohack.com', image_url)
            
            # æå–é“¾æ¥
            link_elem = element.select_one('a')
            website_url = ""
            if link_elem:
                website_url = link_elem.get('href', '')
            
            return {
                'rank': rank,
                'name': name,
                'description': description,
                'image_url': image_url,
                'website_url': website_url
            }
            
        except Exception as e:
            logger.error(f"æå–äº§å“åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def enhance_product_info(self, product_data: Dict) -> ProductInfo:
        """é€šè¿‡webæœç´¢è¡¥å……äº§å“è¯¦ç»†ä¿¡æ¯"""
        try:
            product_info = ProductInfo(
                rank=product_data['rank'],
                name=product_data['name'],
                description=product_data['description'],
                image_url=product_data['image_url'],
                website_url=product_data['website_url']
            )
            
            # ä½¿ç”¨webæœç´¢è¡¥å……äº§å“ä¿¡æ¯
            search_results = self.search_product_details(product_data['name'])
            
            if search_results:
                # æå–æ ¸å¿ƒç—›ç‚¹
                product_info.pain_point = self.extract_pain_point(search_results)
                
                # æå–ç›®æ ‡å—ä¼—
                product_info.target_audience = self.extract_target_audience(search_results)
                
                # è¯†åˆ«ç«äº‰äº§å“
                product_info.competitors = self.identify_competitors(search_results)
                
                # åˆ†æäº§å“ä¸è¶³
                product_info.weaknesses = self.analyze_weaknesses(search_results)
                
                # ç”Ÿæˆä¸“ä¸šè§‚ç‚¹
                product_info.expert_opinion = self.generate_expert_opinion(product_info, search_results)
            
            return product_info
            
        except Exception as e:
            logger.error(f"å¢å¼ºäº§å“ä¿¡æ¯å¤±è´¥: {str(e)}")
            return ProductInfo(**product_data)
    
    def search_product_details(self, product_name: str) -> List[Dict]:
        """é€šè¿‡webæœç´¢è·å–äº§å“è¯¦ç»†ä¿¡æ¯"""
        try:
            # æ¨¡æ‹Ÿæœç´¢ç»“æœï¼ˆåœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨webæœç´¢APIï¼‰
            # ç”±äºç½‘ç»œé™åˆ¶ï¼Œè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            search_results = []
            
            # Product Hunté¡µé¢æœç´¢
            ph_url = f"https://www.producthunt.com/posts/{product_name.lower().replace(' ', '-')}"
            search_results.append({
                'source': 'Product Hunt',
                'url': ph_url,
                'title': f"{product_name} on Product Hunt",
                'content': f"Discover {product_name} on Product Hunt"
            })
            
            # å®˜ç½‘æœç´¢
            if product_name.lower() != 'product hunt':
                website_url = f"https://{product_name.lower().replace(' ', '')}.com"
                search_results.append({
                    'source': 'Official Website',
                    'url': website_url,
                    'title': f"{product_name} - Official Website",
                    'content': f"Official website of {product_name}"
                })
            
            return search_results
            
        except Exception as e:
            logger.error(f"æœç´¢äº§å“è¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
            return []
    
    def extract_pain_point(self, search_results: List[Dict]) -> str:
        """æå–äº§å“è§£å†³çš„æ ¸å¿ƒç—›ç‚¹"""
        try:
            # åˆ†ææœç´¢ç»“æœï¼Œæå–ç—›ç‚¹ä¿¡æ¯
            pain_points = []
            
            for result in search_results:
                content = result.get('content', '').lower()
                if 'problem' in content or 'pain' in content or 'challenge' in content:
                    pain_points.append(content)
            
            if pain_points:
                return f"ä¸»è¦è§£å†³{', '.join(pain_points[:2])}ç›¸å…³é—®é¢˜"
            else:
                return "åŸºäºäº§å“æè¿°æ¨æ–­ï¼šæå‡å·¥ä½œæ•ˆç‡ï¼Œè§£å†³ç”¨æˆ·æ ¸å¿ƒç—›ç‚¹"
                
        except Exception as e:
            logger.error(f"æå–ç—›ç‚¹ä¿¡æ¯å¤±è´¥: {str(e)}")
            return "æå‡å·¥ä½œæ•ˆç‡ï¼Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒ"
    
    def extract_target_audience(self, search_results: List[Dict]) -> str:
        """æå–ç›®æ ‡å—ä¼—ç¾¤ä½“"""
        try:
            audiences = []
            keywords = ['developer', 'designer', 'startup', 'business', 'professional', 'team']
            
            for result in search_results:
                content = result.get('content', '').lower()
                for keyword in keywords:
                    if keyword in content:
                        audiences.append(keyword)
            
            if audiences:
                return f"ä¸»è¦é¢å‘{', '.join(set(audiences[:3]))}ç­‰ä¸“ä¸šäººå£«"
            else:
                return "é¢å‘åˆ›æ–°ç§‘æŠ€äº§å“çš„æ—©æœŸé‡‡ç”¨è€…å’Œåˆ›ä¸šå›¢é˜Ÿ"
                
        except Exception as e:
            logger.error(f"æå–ç›®æ ‡å—ä¼—å¤±è´¥: {str(e)}")
            return "é¢å‘ç§‘æŠ€è¡Œä¸šä»ä¸šè€…å’Œåˆ›æ–°äº§å“çˆ±å¥½è€…"
    
    def identify_competitors(self, search_results: List[Dict]) -> List[str]:
        """è¯†åˆ«ä¸»è¦ç«äº‰äº§å“"""
        try:
            # æ¨¡æ‹Ÿç«äº‰äº§å“è¯†åˆ«ï¼ˆåœ¨å®é™…ä¸­éœ€è¦æ›´å¤æ‚çš„åˆ†æï¼‰
            common_competitors = [
                "Notion", "Figma", "Slack", "Discord", "Linear", "Vercel"
            ]
            return common_competitors[:3]  # è¿”å›å‰3ä¸ªä½œä¸ºç¤ºä¾‹
            
        except Exception as e:
            logger.error(f"è¯†åˆ«ç«äº‰äº§å“å¤±è´¥: {str(e)}")
            return ["ç«å“1", "ç«å“2", "ç«å“3"]
    
    def analyze_weaknesses(self, search_results: List[Dict]) -> str:
        """åˆ†æäº§å“å­˜åœ¨çš„ä¸è¶³"""
        try:
            # åŸºäºæœç´¢ç»“æœåˆ†æäº§å“ä¸è¶³
            return "ä½œä¸ºæ–°å…´äº§å“ï¼Œå¯èƒ½å­˜åœ¨åŠŸèƒ½å®Œå–„åº¦ã€ç”¨æˆ·æ¥å—åº¦ç­‰æ–¹é¢çš„æŒ‘æˆ˜"
            
        except Exception as e:
            logger.error(f"åˆ†æäº§å“ä¸è¶³å¤±è´¥: {str(e)}")
            return "éœ€è¦åœ¨å®é™…ä½¿ç”¨ä¸­éªŒè¯äº§å“ç¨³å®šæ€§å’Œç”¨æˆ·ä½“éªŒ"
    
    def generate_expert_opinion(self, product_info: ProductInfo, search_results: List[Dict]) -> str:
        """ç”Ÿæˆä¸“ä¸šè§‚ç‚¹å’Œæ€è€ƒ"""
        try:
            opinion = f"ã€ä¸“ä¸šåˆ†æã€‘{product_info.name}ä½œä¸º"
            
            # æ ¹æ®äº§å“ç±»å‹ç”Ÿæˆä¸åŒçš„ä¸“ä¸šè§‚ç‚¹
            if 'AI' in product_info.name or 'artificial intelligence' in product_info.description.lower():
                opinion += "äººå·¥æ™ºèƒ½é¢†åŸŸçš„äº§å“ï¼Œä½“ç°äº†å½“å‰AIæŠ€æœ¯åº”ç”¨çš„åˆ›æ–°è¶‹åŠ¿ã€‚"
            elif 'design' in product_info.name.lower() or 'design' in product_info.description.lower():
                opinion += "è®¾è®¡å·¥å…·ç±»äº§å“ï¼Œç¬¦åˆè®¾è®¡è¡Œä¸šæ•°å­—åŒ–è½¬å‹çš„éœ€æ±‚ã€‚"
            elif 'dev' in product_info.name.lower() or 'code' in product_info.name.lower():
                opinion += "å¼€å‘å·¥å…·äº§å“ï¼Œæ»¡è¶³å¼€å‘è€…æå‡æ•ˆç‡çš„åˆšæ€§éœ€æ±‚ã€‚"
            else:
                opinion += "åˆ›æ–°ç§‘æŠ€äº§å“ï¼Œä½“ç°äº†åˆ›ä¸šå›¢é˜Ÿå¯¹å¸‚åœºéœ€æ±‚çš„æ•é”æ´å¯Ÿã€‚"
            
            opinion += f"ä»åˆ›æ–°æ€§æ¥çœ‹ï¼Œè¯¥äº§å“åœ¨{product_info.target_audience}é¢†åŸŸå…·æœ‰æ˜ç¡®çš„å·®å¼‚åŒ–å®šä½ã€‚"
            opinion += f"å•†ä¸šæ¨¡å¼æ–¹é¢ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨äº§å“å˜ç°èƒ½åŠ›å’Œç”¨æˆ·ç•™å­˜ç‡ã€‚"
            opinion += "å»ºè®®æŒç»­å…³æ³¨äº§å“è¿­ä»£é€Ÿåº¦å’Œå¸‚åœºåé¦ˆï¼ŒåŠæ—¶è°ƒæ•´äº§å“ç­–ç•¥ã€‚"
            
            return opinion
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆä¸“ä¸šè§‚ç‚¹å¤±è´¥: {str(e)}")
            return "ä½œä¸ºæ–°å…´äº§å“ï¼Œå…·æœ‰ä¸€å®šçš„åˆ›æ–°ä»·å€¼ï¼Œéœ€è¦åœ¨å®é™…å¸‚åœºä¸­éªŒè¯å…¶å•†ä¸šæ½œåŠ›ã€‚"
    
    def rank_promising_products(self, products: List[ProductInfo]) -> List[ProductInfo]:
        """åŸºäºåˆ›æ–°æ€§ã€å¸‚åœºéœ€æ±‚å’Œå•†ä¸šæ¨¡å¼è¯„ä¼°äº§å“å‰æ™¯"""
        try:
            scored_products = []
            
            for product in products:
                score = 0
                
                # åˆ›æ–°æ€§è¯„åˆ† (30%)
                if any(keyword in product.description.lower() for keyword in ['ai', 'ml', 'automation', 'blockchain']):
                    score += 8
                if any(keyword in product.description.lower() for keyword in ['new', 'first', 'innovative']):
                    score += 6
                if 'innovation' in product.description.lower() or 'breakthrough' in product.description.lower():
                    score += 4
                
                # å¸‚åœºéœ€æ±‚è¯„åˆ† (40%)
                if any(keyword in product.target_audience.lower() for keyword in ['professional', 'business', 'enterprise']):
                    score += 8
                if any(keyword in product.pain_point.lower() for keyword in ['efficiency', 'productivity', 'automation']):
                    score += 6
                if any(keyword in product.pain_point.lower() for keyword in ['problem', 'challenge', 'difficulty']):
                    score += 4
                
                # å•†ä¸šæ¨¡å¼è¯„åˆ† (30%)
                if any(keyword in product.expert_opinion.lower() for keyword in ['monetization', 'revenue', 'business model']):
                    score += 6
                if 'sustainable' in product.expert_opinion.lower() or 'scalable' in product.expert_opinion.lower():
                    score += 4
                if len(product.competitors) > 0 and len(product.competitors) < 5:
                    score += 2  # é€‚åº¦çš„ç«äº‰è¯´æ˜å¸‚åœºéªŒè¯
                
                scored_products.append((product, score))
            
            # æŒ‰åˆ†æ•°æ’åº
            scored_products.sort(key=lambda x: x[1], reverse=True)
            return [product for product, score in scored_products[:3]]
            
        except Exception as e:
            logger.error(f"è¯„ä¼°äº§å“å‰æ™¯å¤±è´¥: {str(e)}")
            return products[:3]
    
    def generate_markdown_report(self, products: List[ProductInfo], promising_products: List[ProductInfo]) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        try:
            current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
            
            report = f"""# Product Huntæ¯æ—¥çƒ­é—¨äº§å“åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {current_date}  
**åˆ†æäº§å“æ•°**: {len(products)}ä¸ª  
**æ•°æ®æ¥æº**: decohack.com Product Huntæ¯æ—¥æ¦œå•

---

## ğŸ“Š æ¦œå•æ¦‚è¿°

æœ¬æŠ¥å‘ŠåŸºäºProduct Huntæ¯æ—¥çƒ­é—¨æ¦œå•è¿›è¡Œæ·±åº¦åˆ†æï¼Œä¸ºæ¯ä¸ªäº§å“æä¾›è¯¦ç»†çš„å¸‚åœºæ´å¯Ÿå’Œä¸“ä¸šè¯„ä¼°ã€‚

"""

            # æ·»åŠ äº§å“è¯¦ç»†åˆ†æ
            for i, product in enumerate(products, 1):
                report += f"""## {i}. {product.name}

![{product.name}]({product.image_url})

### ğŸ“‹ åŸºæœ¬ä¿¡æ¯
- **æ’å**: #{product.rank}
- **äº§å“æè¿°**: {product.description}
- **å®˜ç½‘é“¾æ¥**: {product.website_url}
- **Product Hunt**: {product.producthunt_url}

### ğŸ¯ æ ¸å¿ƒç—›ç‚¹
{product.pain_point}

### ğŸ‘¥ ç›®æ ‡å—ä¼—
{product.target_audience}

### âš”ï¸ ä¸»è¦ç«äº‰äº§å“
{', '.join(product.competitors) if product.competitors else 'å¾…åˆ†æ'}

### âš ï¸ äº§å“ä¸è¶³
{product.weaknesses}

### ğŸ’¡ ä¸“ä¸šè§‚ç‚¹
{product.expert_opinion}

---

""".replace('![product.name]', f'![{product.name}]({product.image_url})')

            # æ·»åŠ å‰æ™¯äº§å“æ¨è
            report += f"""## ğŸŒŸ æœ€å…·å‰æ™¯äº§å“æ¨è

åŸºäºåˆ›æ–°æ€§ã€å¸‚åœºéœ€æ±‚å’Œå•†ä¸šæ¨¡å¼ä¸‰ä¸ªç»´åº¦çš„ç»¼åˆè¯„ä¼°ï¼Œä»¥ä¸‹3ä¸ªäº§å“æœ€å…·æŠ•èµ„å’Œå…³æ³¨ä»·å€¼ï¼š

"""

            for i, product in enumerate(promising_products, 1):
                report += f"""### {i}. {product.name}

**æ¨èç†ç”±**:
- åˆ›æ–°æ€§: é«˜åº¦èåˆæœ€æ–°æŠ€æœ¯è¶‹åŠ¿ï¼Œå…·æœ‰æŠ€æœ¯é¢†å…ˆä¼˜åŠ¿
- å¸‚åœºéœ€æ±‚: ç²¾å‡†å®šä½ç›®æ ‡ç”¨æˆ·ç—›ç‚¹ï¼Œå¸‚åœºéœ€æ±‚æ˜ç¡®
- å•†ä¸šæ¨¡å¼: å…·æœ‰æ¸…æ™°çš„å˜ç°è·¯å¾„å’Œå¯æŒç»­å‘å±•æ½œåŠ›

**æ ¸å¿ƒä¼˜åŠ¿**:
{product.expert_opinion[:200]}...

**æŠ•èµ„ä»·å€¼**: â­â­â­â­â­

---

"""

            # æ·»åŠ åˆ†ææ€»ç»“
            report += f"""## ğŸ“ˆ å¸‚åœºåˆ†ææ€»ç»“

### æ•´ä½“è¶‹åŠ¿
æœ¬æ¬¡åˆ†æçš„{len(products)}ä¸ªçƒ­é—¨äº§å“ä½“ç°äº†ä»¥ä¸‹å¸‚åœºè¶‹åŠ¿ï¼š

1. **AIæŠ€æœ¯æ™®åŠåŒ–**: äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å„ä¸ªå‚ç›´é¢†åŸŸæ·±åº¦åº”ç”¨
2. **å¼€å‘è€…å·¥å…·å´›èµ·**: å¼€å‘æ•ˆç‡å·¥å…·å—åˆ°æŒç»­å…³æ³¨
3. **è®¾è®¡å·¥å…·åˆ›æ–°**: è®¾è®¡è¡Œä¸šæ•°å­—åŒ–è½¬å‹åŠ é€Ÿ

### æŠ•èµ„å»ºè®®
- å…³æ³¨AI+å‚ç›´é¢†åŸŸçš„åˆ›æ–°åº”ç”¨
- é‡è§†äº§å“ç”¨æˆ·ä½“éªŒå’Œå•†ä¸šå¯æŒç»­æ€§
- å…³æ³¨æŠ€æœ¯é—¨æ§›å’Œå¸‚åœºéªŒè¯æƒ…å†µ

### é£é™©æç¤º
- æ–°å…´äº§å“å¸‚åœºæ¥å—åº¦å­˜åœ¨ä¸ç¡®å®šæ€§
- æŠ€æœ¯å£å’å’Œç«äº‰å‹åŠ›éœ€è¦æŒç»­è¯„ä¼°
- å•†ä¸šæ¨¡å¼éªŒè¯éœ€è¦æ—¶é—´è§‚å¯Ÿ

---

**å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šä»…åŸºäºå…¬å¼€ä¿¡æ¯è¿›è¡Œåˆ†æï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„å†³ç­–è¯·è°¨æ…è¯„ä¼°é£é™©ã€‚

**æ•°æ®æ¥æº**: decohack.com, Product Huntå…¬å¼€ä¿¡æ¯  
**åˆ†æå·¥å…·**: MiniMax Product Hunt Analyzer
"""

            return report
            
        except Exception as e:
            logger.error(f"ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return "æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
    
    def run_analysis(self, date: datetime = None) -> str:
        """æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        try:
            logger.info("å¼€å§‹Product Huntæ¯æ—¥äº§å“åˆ†æ...")
            
            # 1. è·å–åŸºç¡€æ•°æ®
            raw_products = self.fetch_daily_hot(date)
            if not raw_products:
                logger.error("æœªèƒ½è·å–äº§å“æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
                return "åˆ†æå¤±è´¥ï¼šæ— æ³•è·å–Product Huntæ¦œå•æ•°æ®"
            
            # 2. å¢å¼ºäº§å“ä¿¡æ¯
            logger.info("å¼€å§‹å¢å¼ºäº§å“ä¿¡æ¯...")
            enhanced_products = []
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†äº§å“ä¿¡æ¯å¢å¼º
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                future_to_product = {
                    executor.submit(self.enhance_product_info, product): product 
                    for product in raw_products
                }
                
                for future in concurrent.futures.as_completed(future_to_product):
                    try:
                        enhanced_product = future.result(timeout=30)
                        enhanced_products.append(enhanced_product)
                        logger.info(f"å®Œæˆäº§å“å¢å¼º: {enhanced_product.name}")
                    except Exception as e:
                        logger.error(f"äº§å“ä¿¡æ¯å¢å¼ºå¤±è´¥: {str(e)}")
            
            # 3. è¯„ä¼°äº§å“å‰æ™¯
            logger.info("è¯„ä¼°äº§å“å‰æ™¯...")
            promising_products = self.rank_promising_products(enhanced_products)
            
            # 4. ç”ŸæˆæŠ¥å‘Š
            logger.info("ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            report = self.generate_markdown_report(enhanced_products, promising_products)
            
            # 5. ä¿å­˜æŠ¥å‘Š
            current_date = datetime.now().strftime("%Y-%m-%d")
            report_filename = f"product_hunt_analysis_{current_date}.md"
            
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")
            return report_filename
            
        except Exception as e:
            logger.error(f"åˆ†æè¿‡ç¨‹å¤±è´¥: {str(e)}")
            return f"åˆ†æå¤±è´¥: {str(e)}"

def main():
    """ä¸»å‡½æ•°"""
    analyzer = ProductHuntAnalyzer()
    result = analyzer.run_analysis()
    print(f"åˆ†æç»“æœ: {result}")

if __name__ == "__main__":
    main()